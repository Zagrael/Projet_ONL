\documentclass[12pt, a4paper]{report}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\arabic{subsection}}
\usepackage[a4paper,left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{graphicx}
\usepackage[french]{babel}
\usepackage[fpms]{umons-coverpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\umonsAuthor{Sabrine \textsc{Riahi}\\Aymerick \textsc{Soyez}}
\usepackage[utf8]{inputenc}
\umonsTitle{Optimisation Non Linéaire}
\umonsSubtitle {\\ \textbf{Récupération d’une image floutée (deblurring)}}
\umonsSupervisor {Sous la direction de Monsieur Nicolas \textsc{Gillis} et Arnaud \textsc{Vandaele}}
\umonsDate {Décembre 2017}
\umonsDocumentType {Projet d'Optimisation}

\begin{document}
\umonsCoverPage
\tableofcontents
\clearpage
\section{Introduction}
Le problème posé est de déflouter une image dont chaque pixel a été remplacé par une combinaison linéaire des pixels voisins. La matrice de floutage utilisée est donnée. De plus, un bruit gaussien a été ajouté dans l'image.\\
L'objectif de ce projet est donc la résolution du problème suivant :\\
\[\underset{0 \leq x \leq 1}{\mathrm{min}} ||Ax - \tilde{x}||_2^2 + \lambda||x||_2^2\]
où :\\
$A$ est la matrice de floutage\\
$\tilde{x}$ est le vecteur de pixels flouté\\
$\lambda$ est un paramètre positif qui dépend du niveau de bruit\\

\section{Étude de la convexité du problème}
\noindent
Pour qu'un problème soit convexe, il faut que
\begin{itemize}
\item Le problème soit sous forme de minimisation,
\item Son domaine $ D $ soit convexe,
\item $\forall x,y \in D,\ \forall \lambda \in \left[0;1\right],\ f(\lambda x + (1 - \lambda)y) \leq \lambda f(x) + (1-\lambda)f(y)$
\end{itemize}
\noindent
\linebreak
Le domaine est décrit par \( D = \left\{ x\ |\ c(x) \geq 0 \right\} \) et est convexe si $c(x)$ est concave.\\
Ici : \( D = \left\{ x\ |\ 0 \leq x \leq 1 \right\}\)\\
On a donc deux inégalités $x \geq 0$ et $1 - x \geq 0$. Ces deux fonctions étant linéaires, elles sont à la fois concaves et convexes, donc ces deux \og sous-domaines\fg\ sont convexes.\\
Puisque l'intersection de deux ensembles convexes est un ensemble convexe, l'ensemble $D$ est également convexe.\\

\noindent
La norme 2 est une fonction convexe.\\

\noindent
\textbf{Preuve}\\
En utilisant les propriétés de la norme euclidienne :\\
$\begin{array}{rcl}
f(\lambda x + (1-\lambda)y) & = & ||\ \lambda x + (1-\lambda)y\ ||\\
 & \leq & \lambda\ ||x|| + (1-\lambda)\ ||y||\\
 & = & \lambda f(x) + (1-\lambda)f(y)\\
\end{array}$

\noindent
\newline
On a donc bien une fonction convexe, et on peut conclure que le problème est convexe.\\


\section{Le problème admet-il un minimum global ?}
Le domaine du problème est compact (fermé et borné). De plus, la fonction est convexe sur ce domaine. On aura donc soit un ou plusieurs minima locaux à l'intérieur du domaine, soit un minimum local sur l'une de ses bornes.\\
Le problème étant convexe, tout minimum local est global.\\
On conclut ainsi que le problème admet un minimum global.\\

\section{Conditions d'optimalité}

\section{Méthode de descente de coordonnées}
La méthode de descente de coordonnées consiste à minimiser successivement chaque variable séparément en gardant les autres variables fixées.\\
\\Pour cela, on choisit un point de départ, qui sera, dans le cadre de ce projet, l'image floutée.\\
On calcule ensuite, pour chaque variable, la dérivée par rapport à celle-ci, que l'on égalise à zéro. La valeur obtenue remplacera la précédente pour les prochaines itérations. \\
\\On effectue ces opérations jusqu'à obtenir une convergence des valeurs obtenues pour chaque variable, c'est à dire jusqu'à ce que l'écart entre les valeurs obtenues soit inférieur à une précision fixée. \\

La fonction que nous devons minimiser est quadratique. Mettons-là sous la forme \[f(x) = \dfrac{1}{2}x^TQx + c^Tx + b\]

\begin{tabular}{rcl}
$||Ax - \tilde{x}||_2^2 + \lambda||x||_2^2$ & = & $(Ax - \tilde{x})^T(Ax - \tilde{x}) + \lambda x^Tx$ \\
 & = & $(Ax)^T(Ax) - \tilde{x}^T(Ax) - (Ax)^T\tilde{x} + \tilde{x}^T\tilde{x} + \lambda x^Tx$ \\
 & = & $x^TA^TAx - 2\tilde{x}^TAx + \tilde{x}^T\tilde{x} + x^T(\lambda I)x$ \\
 & = & $x^T(A^TA + \lambda I)x - 2 \tilde{x}^TAx + \tilde{x}^T\tilde{x}$ \\
\end{tabular}
\newline
\newline

On retrouve bien la forme ci-dessus, avec
$\left\{\begin{array}{rcl}
Q & = & 2(A^TA + \lambda I) \\
c & = & -2A^T\tilde{x} \\
b & = & \tilde{x}^T\tilde{x} \\
\end{array}\right.$

Pour calculer la formule de l'actualisation d'une variable, considérons une fonction quadratique en 3 dimensions : \\
\[f(x_1,x_2,x_3) = \dfrac{1}{2}
\left(\begin{array}{ccc}
x_1 & x_2 & x_3
\end{array}\right)
\left(\begin{array}{ccc}
q_{11} & q_{12} & q_{13} \\
q_{21} & q_{22} & q_{23} \\
q_{31} & q_{32} & q_{33}
\end{array}\right)
\left(\begin{array}{c}
x_1 \\
x_2 \\
x_3
\end{array}\right)
+ \left(\begin{array}{ccc}
c_1 & c_2 & c_3
\end{array}\right)
\left(\begin{array}{c}
x_1 \\
x_2 \\
x_3
\end{array}\right)\]

Si on veut actualiser $x_2$, on calcule la dérivée de $f$ en cette variable :
\[\dfrac{\delta f(x_1,x_2,x_3)}{\delta x_2} = q_{21}x_1 + q_{22}x_2 + q_{23}x_3 + c_2\]
La nouvelle valeur de $x_2$ est donc donnée par :
\(x_2 = \dfrac{-(q_{21}x_1 + q_{23}x_3 + c_2)}{q_{22}}\) \\
Pour une fonction à $n$ dimensions, en la variable $x_i$ :\\
\begin{center}
\begin{tabular}{rcl}
$x_i$ & = & $\dfrac{-\left(\sum\limits_{\underset{j \neq i}{j = 1}}^n q_{ij}x_j + c_i\right)}{q_{ii}}$ \\
 & = & $x_i - \dfrac{\sum\limits_{j = 1}^nq_{ij}x_j + c_i}{q_{ii}}$ \\
 & = & $x_i - \dfrac{\left[\nabla f\right]_i}{q_{ii}}$ \\
\end{tabular}
\end{center}

Pour respecter la contrainte $0 \leq x \leq 1$, il suffit d'utiliser \(\text{min}(\text{max}(..., 0), 1)\), où "..." est la formule d'actualisation ci-dessus. \\

Nous avons également utilisé un test d'arrêt qui prend en compte la norme de l'écart entre les deux dernières itérations ainsi que le nombre d'itérations. \\
L'implémentation sous Matlab se trouve en annexes.

\section{Méthode du gradient}
La méthode du gradient est similaire à la méthode de descente de coordonnées, en prenant comme direction de descente la direction de plus grande pente.\\
Afin de s'assurer que l'objectif diminue, on détermine un pas optimal pour chaque itération.\\
\\Une itération sera donnée par :
\begin{center}
$X_{k+1}=X_k - \alpha \nabla f(X_k)$
\end{center}

\section{Comparaison des méthodes}

\section{Étude de la sensibilité de la solution}


\end{document}